{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343c18df",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q jsonlines\n",
    "!pip install -q kagglehub\n",
    "\n",
    "!pip install -q tensorboardX\n",
    "!pip install -q grain\n",
    "!pip install -q git+https://github.com/google/qwix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a585e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "import functools\n",
    "import humanize\n",
    "import re\n",
    "import urllib.request\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import grain\n",
    "import optax\n",
    "import kagglehub\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from orbax import checkpoint as ocp\n",
    "from qwix import lora\n",
    "from flax import nnx\n",
    "from tunix.examples.gemma_libs import data as data_lib\n",
    "from tunix.examples.gemma_libs import gemma as gemma_lib\n",
    "from tunix.examples.gemma_libs import params as params_lib\n",
    "from tunix.examples.gemma_libs import sampler as sampler_lib\n",
    "from tunix.sft import metrics_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50477930",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "DATA_SRC_URL = (\n",
    "    \"https://raw.githubusercontent.com/openai/grade-school-math/refs/heads/\"\n",
    "    \"master/grade_school_math/data/\"\n",
    ")\n",
    "DATA_DIR = \"./data/\"\n",
    "BATCH_SIZE = 4\n",
    "# Increase `NUM_BATCHES` and `MAX_STEPS` for better results.\n",
    "NUM_BATCHES = 800\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Model\n",
    "MESH = [(1, 4), (\"fsdp\", \"tp\")]\n",
    "# LoRA\n",
    "RANK = 16\n",
    "ALPHA = 2.0\n",
    "\n",
    "# Train\n",
    "LEARNING_RATE = 5e-6\n",
    "B1 = 0.9\n",
    "B2 = 0.99\n",
    "WEIGHT_DECAY = 0.1\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "# GRPO\n",
    "MAX_PROMPT_LENGTH = 256\n",
    "TOTAL_GENERATION_STEPS = 768\n",
    "NUM_GENERATIONS = 4\n",
    "NUM_ITERATIONS = 4\n",
    "BETA = 0.04\n",
    "EPSILON = 0.2\n",
    "TEMPERATURE = 0.9\n",
    "TOP_P = 0.92\n",
    "EVAL_EVERY_N_STEPS = 1\n",
    "MAX_STEPS = 3200 * NUM_EPOCHS\n",
    "\n",
    "# Checkpoint saving\n",
    "CKPT_DIR = \"./ckpts/\"\n",
    "SAVE_INTERVAL_STEPS = 1000\n",
    "MAX_TO_KEEP = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8932f",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with jsonlines.open(path) as reader:\n",
    "        data = list(reader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hbm_usage():\n",
    "    fmt_size = functools.partial(humanize.naturalsize, binary=True)\n",
    "\n",
    "    for d in jax.local_devices():\n",
    "        stats = d.memory_stats()\n",
    "        used = stats[\"bytes_in_use\"]\n",
    "        limit = stats[\"bytes_limit\"]\n",
    "        print(f\"Using {fmt_size(used)} / {fmt_size(limit)} ({used/limit:%}) on {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbatched_generate(sampler, question, total_generation_steps=768):\n",
    "    input_batch = [\n",
    "        TEMPLATE.format(\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            question=question,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    out_data = sampler(\n",
    "        input_strings=input_batch,\n",
    "        total_generation_steps=total_generation_steps,\n",
    "        echo=False,\n",
    "    )\n",
    "    return out_data.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00c357",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb79ad",
   "metadata": {},
   "source": [
    "First, let's define some special tokens. We instruct the model to first reason\n",
    "between the `<start_working_out>` and `<end_working_out>` tokens. After\n",
    "reasoning, we expect it to provide the answer between the `<SOLUTION>` and\n",
    "`</SOLUTION>` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804cd55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_start = \"<start_working_out>\"\n",
    "reasoning_end = \"<end_working_out>\"\n",
    "solution_start = \"<SOLUTION>\"\n",
    "solution_end = \"</SOLUTION>\"\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"You are given a problem.\n",
    "Think about the problem and provide your working out.\n",
    "Place it between {reasoning_start} and {reasoning_end}.\n",
    "Then, provide your solution between {solution_start} and {solution_end}\"\"\"\n",
    "\n",
    "TEMPLATE = \"\"\"<start_of_turn>user\n",
    "{system_prompt}\n",
    "\n",
    "{question}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee7b38",
   "metadata": {},
   "source": [
    "We use OpenAI's GSM8K dataset. GSM8K comprises grade school math word problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    os.path.join(DATA_SRC_URL, \"train.jsonl\"),\n",
    "    os.path.join(DATA_DIR, \"data.jsonl\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6763f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "\n",
    "def get_dataset(path: str) -> grain.MapDataset:\n",
    "\n",
    "    data = load_jsonl(path)\n",
    "\n",
    "    dataset = (\n",
    "        grain.MapDataset.source(data)\n",
    "        .shuffle(seed=SEED)\n",
    "        .map(\n",
    "            lambda x: {\n",
    "                # passed to model forward pass\n",
    "                \"prompts\": TEMPLATE.format(\n",
    "                    system_prompt=SYSTEM_PROMPT, question=x[\"question\"]\n",
    "                ),\n",
    "                # passed to reward functions\n",
    "                \"question\": x[\"question\"],\n",
    "                # passed to reward functions\n",
    "                \"answer\": extract_hash_answer(x[\"answer\"]),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4697094",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\n",
    "    get_dataset(os.path.join(DATA_DIR, \"data.jsonl\"))\n",
    "    .batch(BATCH_SIZE)[:NUM_BATCHES]\n",
    "    .repeat(NUM_EPOCHS)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e8e13",
   "metadata": {},
   "source": [
    "Let's see how one batch of the dataset looks like!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in dataset:\n",
    "    pprint(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3518b8",
   "metadata": {},
   "source": [
    "## Load policy model and reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32543437",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = kagglehub.model_download(f\"abheesht75/gemma-tunix/jax/2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48116207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_model(shard=False):\n",
    "\n",
    "    mesh = jax.make_mesh(*MESH)\n",
    "    abs_gemma: nnx.Module = nnx.eval_shape(\n",
    "        lambda: gemma_lib.Transformer(\n",
    "            gemma_lib.TransformerConfig.gemma_2b(), rngs=nnx.Rngs(params=0)\n",
    "        )\n",
    "    )\n",
    "    abs_state = nnx.state(abs_gemma)\n",
    "    abs_state = jax.tree.map(\n",
    "        lambda a, s: jax.ShapeDtypeStruct(a.shape, jnp.float32, sharding=s),\n",
    "        abs_state,\n",
    "        nnx.get_named_sharding(abs_state, mesh),\n",
    "    )\n",
    "    checkpointer = ocp.StandardCheckpointer()\n",
    "    restored_params = checkpointer.restore(ckpt_path, target=abs_state)\n",
    "\n",
    "    graph_def, _ = nnx.split(abs_gemma)\n",
    "    gemma = nnx.merge(graph_def, restored_params)\n",
    "    return gemma, mesh\n",
    "\n",
    "\n",
    "def get_lora_model(base_model, mesh):\n",
    "    lora_provider = lora.LoraProvider(\n",
    "        module_path=(\n",
    "            \".*q_einsum|.*kv_einsum|.*gate_proj|.*down_proj|.*up_proj|\"\n",
    "            \".*attn_vec_einsum\"\n",
    "        ),\n",
    "        rank=RANK,\n",
    "        alpha=ALPHA,\n",
    "    )\n",
    "\n",
    "    model_input = base_model.get_model_input()\n",
    "    lora_model = lora.apply_lora_to_model(base_model, lora_provider, **model_input)\n",
    "\n",
    "    with mesh:\n",
    "        state = nnx.state(lora_model)\n",
    "        pspecs = nnx.get_partition_spec(state)\n",
    "        sharded_state = jax.lax.with_sharding_constraint(state, pspecs)\n",
    "        nnx.update(lora_model, sharded_state)\n",
    "\n",
    "    return lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e001911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference model\n",
    "gemma, mesh = get_ref_model(ckpt_path)\n",
    "nnx.display(gemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy model\n",
    "lora_gemma = get_lora_model(gemma, mesh=mesh)\n",
    "nnx.display(lora_gemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ade151",
   "metadata": {},
   "source": [
    "## Define reward functions\n",
    "\n",
    "We define four reward functions:\n",
    "\n",
    "- reward if the format of the output exactly matches the instruction given in\n",
    "`TEMPLATE`;\n",
    "- reward if the format of the output approximately matches the instruction given\n",
    "in `TEMPLATE`;\n",
    "- reward if the answer is correct/partially correct;\n",
    "- Sometimes, the text between `<SOLUTION>`, `</SOLUTION>` might not be one number.\n",
    "So, extract the number, and reward the model if the answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1af82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\n",
    "    rf\"{solution_start}(.+?){solution_end}\"\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags=re.MULTILINE | re.DOTALL,\n",
    ")\n",
    "\n",
    "match_format.search(\n",
    "    \"<start_working_out>Let me think!<end_working_out><SOLUTION>2</SOLUTION>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c33a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_format_exactly(prompts, completions, **kargs):\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion\n",
    "        # Match if format is seen exactly!\n",
    "        if match_format.search(response) is not None:\n",
    "            score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_format_approximately(prompts, completions, **kargs):\n",
    "    scores = []\n",
    "\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion\n",
    "        # Count how many keywords are seen - we penalize if too many!\n",
    "        # If we see 1, then plus some points!\n",
    "        score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(reasoning_end) == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_end) == 1 else -0.5\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer(prompts, completions, answer, **kargs):\n",
    "    responses = completions\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1) if (guess := match_format.search(r)) is not None else None\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        score = 0\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # Correct answer gets 3 points!\n",
    "        if guess == true_answer:\n",
    "            score += 3.0\n",
    "        # Match if spaces are seen\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            score += 1.5\n",
    "        else:\n",
    "            # We also reward it if the answer is close via ratios!\n",
    "            # Ie if the answer is within some range, reward it!\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if ratio >= 0.9 and ratio <= 1.1:\n",
    "                    score += 0.5\n",
    "                elif ratio >= 0.8 and ratio <= 1.2:\n",
    "                    score += 0.25\n",
    "                else:\n",
    "                    score -= 1.0  # Penalize wrong answers\n",
    "            except:\n",
    "                score -= 0.5  # Penalize\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8620873",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_numbers = re.compile(\n",
    "    rf\"{solution_start}.*?([\\d\\.]{{1,}})\", flags=re.MULTILINE | re.DOTALL\n",
    ")\n",
    "match_numbers.findall(\"<SOLUTION>  0.34  </SOLUTION>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_numbers(prompts, completions, answer, **kargs):\n",
    "    question = kargs[\"question\"]\n",
    "    # question = prompts[0][-1][\"content\"]\n",
    "    responses = completions\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1) if (guess := match_numbers.search(r)) is not None else None\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    print(\"START ============================\")\n",
    "    print(f\"Question: {question[0]}\")\n",
    "    print(f\"Answer: {answer[0]}\")\n",
    "    print(f\"Response: {responses[0]}\")\n",
    "    print(f\"Extracted: {extracted_responses[0]}\")\n",
    "    print(\"END ==============================\")\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # Convert to numbers\n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            guess = float(guess.strip())\n",
    "            scores.append(1.5 if guess == true_answer else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8c61c",
   "metadata": {},
   "source": [
    "## Generate\n",
    "\n",
    "Before we train the model, let's see the model outputs so that we can compare\n",
    "them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56675ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_tokenizer = data_lib.GemmaTokenizer()\n",
    "sampler = sampler_lib.Sampler(transformer=lora_gemma, vocab=gemma_tokenizer.vocab)\n",
    "\n",
    "question = (\n",
    "    \"Trevor and two of his neighborhood friends go to the toy shop every year \"\n",
    "    \"to buy toys. Trevor always spends $20 more than his friend Reed on toys, \"\n",
    "    \"and Reed spends 2 times as much money as their friend Quinn on the toys. \"\n",
    "    \"If Trevor spends $80 every year to buy his toys, calculate how much money \"\n",
    "    \"in total the three spend in 4 years.\"\n",
    ")\n",
    "print(unbatched_generate(sampler, question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc535a76",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ckpt saving\n",
    "checkpointing_options = ocp.CheckpointManagerOptions(\n",
    "    save_interval_steps=SAVE_INTERVAL_STEPS, max_to_keep=MAX_TO_KEEP\n",
    ")\n",
    "\n",
    "# Metrics logger\n",
    "metrics_logging_options = metrics_logger.MetricsLoggerOptions(\n",
    "    log_dir=\"/tmp/tensorboard/grpo\", flush_every_n_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dde978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "training_config = GrpoTrainingConfig(\n",
    "    max_prompt_length=MAX_PROMPT_LENGTH,\n",
    "    total_generation_steps=TOTAL_GENERATION_STEPS,\n",
    "    num_generations=NUM_GENERATIONS,\n",
    "    num_iterations=NUM_ITERATIONS,\n",
    "    beta=BETA,\n",
    "    epsilon=EPSILON,\n",
    "    temperature=TEMPERATURE,\n",
    "    top_p=TOP_P,\n",
    "    eval_every_n_steps=EVAL_EVERY_N_STEPS,\n",
    "    max_steps=MAX_STEPS,\n",
    "    # max_grad_norm=0.1,\n",
    "    # metrics logging\n",
    "    metrics_logging_options=metrics_logging_options,\n",
    "    # checkpoint saving\n",
    "    checkpoint_root_directory=CKPT_DIR,\n",
    "    checkpointing_options=checkpointing_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53559a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_tokenizer = data_lib.GemmaTokenizer()\n",
    "sampler = sampler_lib.Sampler(\n",
    "    transformer=lora_gemma,\n",
    "    vocab=gemma_tokenizer.vocab,\n",
    ")\n",
    "\n",
    "grpo_trainer = GrpoTrainer(\n",
    "    model=lora_gemma,\n",
    "    ref_model=gemma,  # use the base model as reference\n",
    "    reward_fns=[\n",
    "        match_format_exactly,\n",
    "        match_format_approximately,\n",
    "        check_answer,\n",
    "        check_numbers,\n",
    "    ],\n",
    "    sampler=sampler,\n",
    "    optimizer=optax.adamw(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        b1=B1,\n",
    "        b2=B2,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    ),\n",
    "    training_config=training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHARD:\n",
    "    with mesh:\n",
    "        if DO_MEM_PROFILING:\n",
    "            with profile_and_capture_log(\"gemma_benchmark\"):\n",
    "                grpo_trainer.train(dataset)\n",
    "        else:\n",
    "            grpo_trainer.train(dataset)\n",
    "else:\n",
    "    if DO_MEM_PROFILING:\n",
    "        with profile_and_capture_log(\"gemma_benchmark\"):\n",
    "            grpo_trainer.train(dataset)\n",
    "    else:\n",
    "        grpo_trainer.train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931fb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc546bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
